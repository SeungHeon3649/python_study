{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjQlu44vkITIkTn19xZh3W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DblZWVCWwNGU","executionInfo":{"status":"ok","timestamp":1695618799926,"user_tz":-540,"elapsed":23655,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"b56fd24f-eb10-4b08-e2f3-7c440b941524"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!tar -zxvf \"C:\\Users\\gjaischool\\study_is_good\\python_study\\opencv_aischool\\annotation.tar\"\n","!tar -zxvf \"C:\\Users\\gjaischool\\study_is_good\\python_study\\opencv_aischool\\images.tar\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oC0mXBNwRvM","executionInfo":{"status":"ok","timestamp":1695618865943,"user_tz":-540,"elapsed":508,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"61cfd0be-9768-4435-cb71-d58ad01ed8fb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tar (child): Cannot connect to C: resolve failed\n","\n","gzip: stdin: unexpected end of file\n","tar: Child returned status 128\n","tar: Error is not recoverable: exiting now\n","tar (child): Cannot connect to C: resolve failed\n","\n","gzip: stdin: unexpected end of file\n","tar: Child returned status 128\n","tar: Error is not recoverable: exiting now\n"]}]},{"cell_type":"code","source":["from keras.utils import Sequence\n","from keras.models import Model\n","from keras.layers import Input,Activation,Conv2D,BatchNormalization,SeparableConv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose,add\n","import os\n","from keras.preprocessing.image import load_img\n","import numpy as np\n","import random\n","\n","input_dir='./images/'\n","target_dir='./annotations/trimaps/'\n","img_size=(160,160)\n","n_calss=3 #분할 레이블(1:물체,2:배경,3:경계)\n","batch_size=32\n","\n","img_paths=sorted([os.path.join(input_dir,f)\n","                  for f in os.listdir(input_dir)\n","                  if f.endswith('.jpg')])\n","label_paths=sorted([os.path.join(target_dir,f)\n","                    for f in os.listdir(target_dir)\n","                    if f.endswith('.png') and not f.startswith('.')])\n","\n","class N_m_data(Sequence):\n","    def __init__(self,batch_size,img_size,img_paths,label_paths):\n","        self.batch_size=batch_size\n","        self.img_size=img_size\n","        self.img_paths=img_paths\n","        self.label_paths=label_paths\n","\n","    def __len__(self):\n","        return len(self.label_paths)//self.batch_size\n","\n","    def __getitem__(self, index):\n","        idx=index*self.batch_size\n","        batch_img_paths=self.img_paths[idx:idx+self.batch_size]\n","        batch_label_paths=self.label_paths[idx:idx+self.batch_size]\n","        x=np.zeros((self.batch_size,)+self.img_size+(3,),'float32')\n","        for i,path in enumerate(batch_img_paths):\n","            img = load_img(path,target_size=self.img_size)\n","            x[i] = img\n","        y=np.zeros((self.batch_size,)+self.img_size+(1,),'uint8')\n","        for i,path in enumerate(batch_label_paths):\n","            img = load_img(path,target_size=self.img_size,color_mode='grayscale')\n","            y[i] = np.expand_dims(img,2)\n","            y[i]-=1 #부류번호 1,2,3 -> 0,1,2\n","        return x,y\n","\n","def mk_model(img_size,n_class):\n","    inputs=Input(shape=img_size+(3,))\n","\n","    #U_net 다운샘플링(축소 경로)\n","    x=Conv2D(32,3,strides=2,padding='same')(inputs)\n","    x=BatchNormalization()(x)\n","    x=Activation(\"relu\")(x)\n","    pre_block_act=x #(지름길 경로 연결을 위한 값)\n","\n","    for filt in [64,128,256]:\n","        x=Activation('relu')(x)\n","        x=SeparableConv2D(filt,3,padding='same')(x)\n","        x=BatchNormalization()(x)\n","        x=Activation('relu')(x)\n","        x=SeparableConv2D(filt,3,padding='same')(x)\n","        x=BatchNormalization()(x)\n","        x=MaxPooling2D(3,strides=2,padding='same')(x)\n","        residual=Conv2D(filt,1,strides=2,padding='same')(pre_block_act)\n","        x=add([x,residual])#지름길 연결\n","        pre_block_act = x#(지름길 경로 연결을 위한 값)\n","\n","    #U_net 업샘플링(확대 경로)\n","    for filt in [256,128,64,32]:\n","        x=Activation('relu')(x)\n","        x=Conv2DTranspose(filt,3,padding='same')(x)\n","        x=BatchNormalization()(x)\n","        x=Activation('relu')(x)\n","        x=Conv2DTranspose(filt,3,padding='same')(x)\n","        x=BatchNormalization()(x)\n","        x=UpSampling2D(2)(x)\n","        residual=UpSampling2D(2)(pre_block_act)\n","        residual=Conv2D(filt,1,padding='same')(residual)\n","        x=add([x,residual])#지름길 연결\n","        pre_block_act = x\n","\n","    outputs=Conv2D(n_class,3,activation=\"softmax\",padding=\"same\")(x)\n","    m = Model(inputs,outputs)\n","    return m\n","\n","random.Random(1).shuffle(img_paths)\n","random.Random(1).shuffle(label_paths)\n","tt_samp=int(len(img_paths)*0.1)#10%태스트 데이터\n","tr_img_paths=img_paths[:-tt_samp]\n","tr_label_paths=label_paths[:-tt_samp]\n","tt_img_paths=img_paths[-tt_samp:]\n","tt_label_paths=label_paths[-tt_samp:]\n","\n","tr_dataset=N_m_data(batch_size,img_size,tr_img_paths,tr_label_paths)\n","tt_dataset=N_m_data(batch_size,img_size,tt_img_paths,tt_label_paths)\n","\n","m=mk_model(img_size,n_calss)\n","\n","m.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='acc')\n","from keras.callbacks import ModelCheckpoint\n","cb=[ModelCheckpoint(\"u_net_m.h5\",save_best_only=True)]\n","m.fit(tr_dataset,epochs=30,validation_data=tt_dataset,callbacks=cb)"],"metadata":{"id":"aHH-YhzLwpay"},"execution_count":null,"outputs":[]}]}