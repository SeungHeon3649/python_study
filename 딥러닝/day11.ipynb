{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNc+Fn9H7NXnRi3TgUEWwAG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"n36pNc3yFH64"},"outputs":[],"source":["import numpy as np\n","from keras.datasets import imdb"]},{"cell_type":"code","source":["(train_x, train_y), (test_x, test_y) = imdb.load_data(num_words = 100)"],"metadata":{"id":"BsJgasTmz_xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(train_x)):\n","    train_x[i] = [w for w in train_x[i] if w > 2]\n","for i in range(len(test_x)):\n","    test_x[i] = [w for w in test_x[i] if w > 2]"],"metadata":{"id":"nQFL-PVMOg0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i2w = {d[i]:i for i in d}\n","for w in train_x[0]:\n","    print(i2w[w-3], end = ' ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPM4_VfRLRUh","executionInfo":{"status":"ok","timestamp":1693546829724,"user_tz":-540,"elapsed":355,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"671951c1-86ff-4443-ae19-a5bdb420c4ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["this film was just story really the they and you just there is an and the from the as so i the there was a with this film the the film were great it was just so much that i the film as as it was for and would it to to and the was really at the it was so and you what they if you at a film it have been good and this was also to the that the of and they were just are out of the i because the that them all up are a for the film but are and be for what they have don't you the story was so because it was and was all that was with all "]}]},{"cell_type":"code","source":["train_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhNRVhh_2B_d","executionInfo":{"status":"ok","timestamp":1693539911807,"user_tz":-540,"elapsed":2,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"4bd2c5eb-f7db-4bf6-92b2-5b1e03df2db5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["len(imdb.get_word_index())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JcM29752DsH","executionInfo":{"status":"ok","timestamp":1693540188412,"user_tz":-540,"elapsed":917,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"e0261d51-99ea-478c-a16a-1c2717582eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["88584"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["d = imdb.get_word_index()"],"metadata":{"id":"hKI1WwqF3Hop"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ck_d = [w for w in d.items()]\n","sorted(ck_d, key = lambda x:x[1])[0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__5xlyTzIPPw","executionInfo":{"status":"ok","timestamp":1693544915485,"user_tz":-540,"elapsed":2,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"13e33baa-ec05-442b-f4fa-70d0259c3aa1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5)]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["train_x[0]"],"metadata":{"id":"lZP3yHIpJLx9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_train_x = []\n","for i in range(len(train_x)):\n","    s_train_x.append([w for w in train_x[i] if w > 2])\n","s_train_x"],"metadata":{"id":"O7KNmAoLJ30O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_test_x = []\n","for i in range(len(train_x)):\n","    s_test_x.append([w for w in test_x[i] if w > 2])\n","s_test_x"],"metadata":{"id":"Ttp0OzAOOLdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing import sequence\n","sequence\n"],"metadata":{"id":"Hj9sSuL7Lgo1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"IQTkj2NEjteV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNN:\n","    def __init__(self, n_cells = 10, bs = 32, lr = 0.01):\n","        self.n_cells = n_cells\n","        self.w1x = None\n","        self.w1h = None\n","        self.b1 = None\n","        self.w2 = None\n","        self.b2 = None\n","        self.h = None\n","        self.losses = []\n","        self.val_losses = []\n","        self.bs = bs\n","        self.lr = lr\n","\n","    def forpass(self, x):\n","        self.h = [np.zeros(x.shape[0].self.n_cells)]\n","        seq = np.swapaxes(x, 0.1)\n","        for x in seq:\n","            z1 = x@self.w1x + self.h[-1]@self.w1h + self.b1\n","            h = np.tanh(z1)\n","            self.h.append(h)\n","            z2 = h@self.w2 + self.b2\n","        return z2\n","\n","    def backprop(self, x, err):\n","        m = len(x)\n","        w2_g = (self.h[-1].T@err) / m\n","        b2_g = np.sum(err) / m\n","\n","        seq = np.swapaxes(x, 0.1)\n","        w1x_g = w1h_g = b1_g = 0\n","        c_err = err@self.w2.T*(1 - self.h[-1]**2)\n","\n","        for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]):\n","            w1h_g += h.T@c_err\n","            w1x_g += x.T@c_err\n","            b1_g += np.sum(c_err, axis = 0)\n","            c_err = c_err@self.w1h.T*(1 - h**2)\n","\n","        w1h_g /= m\n","        w1x_g /= m\n","        b1_g /= m\n","\n","        return w1h_g, w1x_g, b1_g, w2_g, b2_g\n","\n","    def sigmoid(self, z):\n","        z = np.clip(z, -100, None)\n","        a = 1/(1 + np.exp(-z))\n","        return a\n","\n","    def init_w(self, n_f, n_c):\n","        orth = tf.initializers.Orthogonal()\n","        glorot = tf.initializers.GlorotUniform(0)\n","\n","        self.w1h = orth((self.n_cells, self.n_cells)).numpy()\n","        self.wq1x = glorot((n_f, self.n_cells)).numpy()\n","        self.b1 = np.zeros(self.n_cells)\n","\n","        self.w2 = glorot((self.n_cells, n_c)).numpy()\n","        self.b2 = np.zeros(n_c)\n","\n","    def fit(self, x, y, epochs = 100, val_x = None, val_y = None):\n","        y = y.reshape(-1, 1)\n","        val_y = val_y.reshape(-1, 1)\n","        np.random.seed(42)\n","        self.init_w(x.shape[2], y.shape[1])\n","        for i in range(epochs):\n","            b_loss = []\n","            for x_b, y_b in self.gen_bs(x, y):\n","                a = self.training(x_b, y_b)\n","                a = np.clip(a, 1e-10, 1-1e-10)\n","                loss = np.mean(-(y_b*np.log(a) + (1 - y)*np.log(1 - a)))\n","                b_loss.append(loss)\n","            self.losses.append(np.mean(b_loss))\n","            self.update_val_loss(val_x, val_y)\n","            print(f\"에포크 {i + 1} : train_loss{self.losses[-1]}\")\n","    def gen_bs(self, x, y):\n","        l = len(x)\n","        bins = l//self.bs\n","        if i % self.bs:\n","            bins += 1\n","        idx = np.random.permutation(np.arange(len(x)))\n","        x = x[idx]\n","        y = y[idx]\n","        for i in range(bins):\n","            st = self.bs * i\n","            end = self.bs * (i + 1)\n","            yield x[st:end], y[st:end]\n","\n","    def training(self, x, y):\n","        m = len(x)\n","        z = self.forpass(x)\n","        a = self.sigmoid(z)\n","        err = -(y - a)\n","\n","        w1h_g, w1x_g, b1_g, w2_g, b2_g = self.backprop(x, err)\n","\n","        self.w1h -= self.lr * w1h_g\n","        self.w1x -= self.lr * w1x_g\n","        self.b1 -= self.lr*b1_g\n","        self.w2 -= self.lr.w2_g\n","        self.b2 -= self.lr*b2_g\n","\n","        return a\n","\n","    def update_val_loss(self, val_x, val_y):\n","        z = self.forpass(val_x)\n","        a = self.sigmoid(z)\n","        a = np.clip(a, 1e-10, 1-1e-10)\n","        val_loss = np.mean(-(val_y * np.log(a) + (1 - val_y) * np.log(1-a)))\n","        self.val_losses.append(val_loss)\n","\n","    def predict(self, x):\n","        z = self.forpass(x)\n","        a = self.sigmoid(z)\n","        return a > 0.5\n","\n","    def score(self, x, y):\n","        py = self.predict(x)\n","        ty = y.reshape(-1, 1)\n","        np.mean(ty == py)"],"metadata":{"id":"b1KG59-cV66i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense, Embedding\n","from keras.losses import binary_crossentropy"],"metadata":{"id":"Zej6V8RbpqBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from keras.datasets import imdb\n","from keras.utils import pad_sequences\n","from keras.utils import to_categorical\n","(tr_x,tr_y),(tt_x,tt_y)=imdb.load_data(num_words=100) # 정수인코딩이 끝난 상태(문장이 숫자로 되어있음)\n","for i in range(len(tr_x)):\n","  tr_x[i]=[w for w in tr_x[i] if w > 2]\n","for i in range(len(tt_x)):\n","  tt_x[i]=[w for w in tt_x[i] if w > 2]\n","np.random.seed(42)\n","r_idx=np.random.permutation(25000)\n","s_tr_x=tr_x[r_idx[:20000]]\n","s_tr_y=tr_y[r_idx[:20000]]\n","s_tt_x=tr_x[r_idx[20000:]]\n","s_tt_y=tr_y[r_idx[20000:]]\n","\n","# 패딩(단어의 길이를 맞춰줌) 패딩 : 데이터의 크기를 맞춰줌\n","p_tr_x=pad_sequences(s_tr_x,maxlen=100)\n","p_tt_x=pad_sequences(s_tt_x,maxlen=100)\n","s_tr_x=to_categorical(p_tr_x)\n","s_tt_x=to_categorical(p_tt_x)"],"metadata":{"id":"mla23aBahFev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_tr_x.shape"],"metadata":{"id":"MWPYDFmwhGzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(s_tr_y)"],"metadata":{"id":"jnp3GthlhHiQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m = Sequential(name=\"RNN\")\n","m.add(SimpleRNN(100,input_shape=s_tr_x.shape[1:]))\n","m.add(Dense(1,activation='sigmoid'))\n","m.summary()"],"metadata":{"id":"bQ6W8UDWqwCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s_tr_x.shape,s_tr_y.shape,s_tt_x.shape,s_tt_y.shape"],"metadata":{"id":"SR-vIO48hJDO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint,EarlyStopping\n","ck=ModelCheckpoint(\"b_rnn_m.h5\",save_best_only=True)\n","es=EarlyStopping(patience=5)\n","m.compile(loss='binary_crossentropy',metrics='acc')\n","hy=m.fit(s_tr_x,s_tr_y,validation_data=(s_tt_x,s_tt_y),epochs=100,batch_size=64,callbacks=[ck,es],verbose=2)"],"metadata":{"id":"DMC0t56_hJxm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lLFOAYXSkuun"},"execution_count":null,"outputs":[]}]}