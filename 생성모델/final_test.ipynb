{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyOK9YKDGzlFiGd9e2enwCo+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"QBKX4hC9l7zo","executionInfo":{"status":"error","timestamp":1698636306943,"user_tz":-540,"elapsed":782,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"501bdecf-45d1-4349-a7ae-9a92c20f45b4"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b3d81455afba>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_di_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_g_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_gan_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-b3d81455afba>\u001b[0m in \u001b[0;36mmake_gan_m\u001b[0;34m(G, D)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_gan_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'trainable'"]}],"source":["from keras.datasets import fashion_mnist\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras.layers import Dense,Conv2D,Conv2DTranspose,Flatten,Reshape,RepeatVector,LSTM,LeakyReLU,Dropout\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","\n","(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n","\n","train_x = train_x.astype(np.float32) / 255.\n","test_x = test_x.astype(np.float32) / 255.\n","\n","\n","def make_di_m():\n","    panbyeol = Sequential([\n","        Conv2D(64,3,padding='same',activation=LeakyReLU(0.2),input_shape= (28, 28, 1)),\n","        Conv2D(128,3,2,padding='same',activation=LeakyReLU(0.2)),\n","        Conv2D(128,3,2,padding='same',activation=LeakyReLU(0.2)),\n","        Conv2D(256,3,2,padding='same',activation=LeakyReLU(0.2)),\n","        Flatten(),\n","        Dropout(0.4),\n","        Dense(10,activation='sigmoid')\n","    ])\n","\n","def make_g_m():\n","    sangsung = Sequential([\n","        Dense(4*4*256,activation=LeakyReLU(0.2),input_dim = 100),\n","        Reshape((4,4,256)),\n","        Conv2DTranspose(128,4,2,padding='same', activation=LeakyReLU(0.2)),\n","        Conv2DTranspose(128,4,2,padding='same', activation=LeakyReLU(0.2)),\n","        Conv2DTranspose(128,4,2,padding='same', activation=LeakyReLU(0.2)),\n","        Conv2D(3, 3, padding = 'same', activation='tanh')\n","    ])\n","\n","def make_gan_m(G, D):\n","  D.trainable = False\n","  m = Sequential([G,D])\n","  m.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0002,beta_1=0.5))\n","  return m\n","\n","epochs = 10\n","batch_size = 32\n","c_size = 100\n","\n","def g_re_img(data,bc_size):\n","  idx = np.random.randint(0,data.shape[0],bc_size)\n","  x = data[idx]\n","  y = np.ones((bc_size,1))\n","  return x,y\n","\n","def g_g_img(G,c_size,bc_size):\n","  z = np.random.randn(bc_size,c_size)\n","  x = G.predict(z,verbose=0)\n","  y = np.zeros((bc_size,1))\n","  return x,y\n","\n","def train(G,D,GAN,data,c_size,bc_size,ep,v=0):\n","  n_bc=int(data.shape[0]/bc_size)\n","  for i in range(1,ep+1):\n","    for bc in range(n_bc):\n","      re_x,re_y=g_re_img(data,bc_size//2)\n","      d_loss1 = D.train_on_batch(re_x,re_y)\n","      g_x,g_y=g_g_img(G,c_size,bc_size//2)\n","      d_loss2 = D.train_on_batch(g_x,g_y)\n","\n","      z = np.random.randn(bc_size,c_size)\n","      gn_y = np.ones((bc_size,1))\n","      g_loss = GAN.train_on_batch(z,gn_y)\n","\n","    if v==1:\n","      print(f\"{i}회: 판별_loss(re):{d_loss1[0]}, 판별_loss(g):{d_loss2[0]},GAN_loss:{g_loss}\")\n","    if i%10==0:\n","      plt.figure(figsize=(20,2))\n","      plt.suptitle(f\"E:{i}\")\n","      ck_x,ck_y=g_g_img(G,c_size,10)\n","      for n in range(10):\n","        plt.subplot(1,10,n+1)\n","        plt.imshow((ck_x[n]+1)/2.0,cmap='gray')\n","        plt.axis('off')\n","      plt.show()\n","\n","D = make_di_m()\n","G = make_g_m()\n","GAN = make_gan_m(G,D)\n","train(G, D, GAN, train_x, c_size, batch_size, epochs, 1)"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import sys\n","\n","def c_yolov3():\n","    f = open('coco_names.txt', 'r')\n","    c_l = [i.strip() for i in f]\n","    m = cv2.dnn.readNet(\"yolov3.weights\", 'yolov3.cfg')\n","\n","    l_name = m.getLayerNames()\n","    out_ls = [l_name[i - 1] for i in m.getUnconnectedOutLayers()]\n","\n","    return m,out_ls,c_l\n","\n","model, out_ls, class_name = c_yolov3()\n","colors = np.random.uniform(0, 255, (len(class_name), 3))\n","img = cv2.imread(\"lenna.png\")\n","if img is None:\n","    sys.exit(\"Image load failed\")\n","\n","def yolov3_detect(img,model, out_ls):\n","    oh,ow = img.shape[0], img.shape[1]\n","    t_img = cv2.dnn.blobFromImage(img, 1.0/256, (416, 416), (0, 0, 0), swapRB=True)\n","    model.setInput(t_img)\n","    out_3 = model.forward(out_ls)\n","\n","    box, conf, id = [], [], []\n","    for out_put in out_3:\n","        for vec85 in out_put:\n","            sc = vec85[5:]\n","            c_l_id = np.argmax(sc)\n","            conf_d = sc[c_l_id]\n","            if conf_d > 0.7:\n","                c_x, c_y = int(vec85[0] * ow), int(vec85[1] * oh)\n","                w, h = int(vec85[2] * ow), int(vec85[3] * oh)\n","                x, y = int(c_x - w / 2), int(c_y - h / 2)\n","                box.append([x, y, x+w, y+h])\n","                conf.append(float(conf_d))\n","                id.append(c_l_id)\n","    ind = cv2.dnn.NMSBoxes(box, conf, 0.5, 0.4)\n","    oj= [box[i] + [conf[i]] + [id[i]] for i in range(len(box)) if i in ind]\n","    return oj\n","\n","res = yolov3_detect(img, model, out_ls)\n","\n","for i in range(len(res)):\n","    sx, sy, ex, ey, conf, id = res[i]\n","    text = str(class_name[id]) + f'{conf:.3f}'\n","    cv2.rectangle(img, (sx, sy), (ex, ey), colors[id], 2)\n","    cv2.putText(img, text, (sx, sy + 30), cv2.FONT_HERSHEY_PLAIN, 1.5, colors[id], 2)\n","cv2.imshow(\"dst\", img)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"fuGUmDaQpTaQ","executionInfo":{"status":"error","timestamp":1698637269825,"user_tz":-540,"elapsed":6845,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"f40d39db-ddaa-44c9-d950-9c372a312731"},"execution_count":3,"outputs":[{"output_type":"error","ename":"DisabledFunctionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e8fb32e1a12b>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_PLAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dst\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"],"errorDetails":{"actions":[{"action":"open_snippet","actionText":"Search Snippets for cv2.imshow","snippetFilter":"cv2.imshow"}]}}]}]}