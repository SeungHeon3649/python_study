{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNwqYksvxB8TI75JqIRrdFT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2GWtpjwcgJ0","executionInfo":{"status":"ok","timestamp":1695278580790,"user_tz":-540,"elapsed":396310,"user":{"displayName":"이승헌","userId":"04831998974445952395"}},"outputId":"681dd0f8-8362-4273-9e76-b8aa19f6a00e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/100\n","469/469 - 18s - loss: 0.2580 - acc: 0.9188 - val_loss: 0.0567 - val_acc: 0.9833 - 18s/epoch - 37ms/step\n","Epoch 2/100\n","469/469 - 3s - loss: 0.0713 - acc: 0.9779 - val_loss: 0.0344 - val_acc: 0.9886 - 3s/epoch - 7ms/step\n","Epoch 3/100\n","469/469 - 3s - loss: 0.0494 - acc: 0.9849 - val_loss: 0.0301 - val_acc: 0.9891 - 3s/epoch - 7ms/step\n","Epoch 4/100\n","469/469 - 3s - loss: 0.0397 - acc: 0.9877 - val_loss: 0.0278 - val_acc: 0.9909 - 3s/epoch - 7ms/step\n","Epoch 5/100\n","469/469 - 4s - loss: 0.0348 - acc: 0.9890 - val_loss: 0.0235 - val_acc: 0.9914 - 4s/epoch - 8ms/step\n","Epoch 6/100\n","469/469 - 3s - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0210 - val_acc: 0.9931 - 3s/epoch - 7ms/step\n","Epoch 7/100\n","469/469 - 3s - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0221 - val_acc: 0.9929 - 3s/epoch - 7ms/step\n","Epoch 8/100\n","469/469 - 4s - loss: 0.0239 - acc: 0.9923 - val_loss: 0.0202 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 9/100\n","469/469 - 3s - loss: 0.0226 - acc: 0.9925 - val_loss: 0.0262 - val_acc: 0.9912 - 3s/epoch - 7ms/step\n","Epoch 10/100\n","469/469 - 3s - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0219 - val_acc: 0.9936 - 3s/epoch - 7ms/step\n","Epoch 11/100\n","469/469 - 3s - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0196 - val_acc: 0.9938 - 3s/epoch - 7ms/step\n","Epoch 12/100\n","469/469 - 4s - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0178 - val_acc: 0.9943 - 4s/epoch - 8ms/step\n","Epoch 13/100\n","469/469 - 3s - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0203 - val_acc: 0.9934 - 3s/epoch - 7ms/step\n","Epoch 14/100\n","469/469 - 3s - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0214 - val_acc: 0.9937 - 3s/epoch - 7ms/step\n","Epoch 15/100\n","469/469 - 4s - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0211 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 16/100\n","469/469 - 4s - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0192 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 17/100\n","469/469 - 3s - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 0.9942 - 3s/epoch - 7ms/step\n","Epoch 18/100\n","469/469 - 4s - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0215 - val_acc: 0.9944 - 4s/epoch - 8ms/step\n","Epoch 19/100\n","469/469 - 4s - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0230 - val_acc: 0.9933 - 4s/epoch - 8ms/step\n","Epoch 20/100\n","469/469 - 3s - loss: 0.0107 - acc: 0.9962 - val_loss: 0.0217 - val_acc: 0.9941 - 3s/epoch - 7ms/step\n","Epoch 21/100\n","469/469 - 3s - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0198 - val_acc: 0.9944 - 3s/epoch - 7ms/step\n","Epoch 22/100\n","469/469 - 4s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0229 - val_acc: 0.9930 - 4s/epoch - 8ms/step\n","Epoch 23/100\n","469/469 - 3s - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0257 - val_acc: 0.9942 - 3s/epoch - 7ms/step\n","Epoch 24/100\n","469/469 - 3s - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0224 - val_acc: 0.9933 - 3s/epoch - 7ms/step\n","Epoch 25/100\n","469/469 - 4s - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0231 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 26/100\n","469/469 - 4s - loss: 0.0096 - acc: 0.9966 - val_loss: 0.0219 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 27/100\n","469/469 - 3s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0253 - val_acc: 0.9934 - 3s/epoch - 7ms/step\n","Epoch 28/100\n","469/469 - 3s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0227 - val_acc: 0.9935 - 3s/epoch - 7ms/step\n","Epoch 29/100\n","469/469 - 4s - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0251 - val_acc: 0.9934 - 4s/epoch - 8ms/step\n","Epoch 30/100\n","469/469 - 4s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0232 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 31/100\n","469/469 - 4s - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0263 - val_acc: 0.9937 - 4s/epoch - 8ms/step\n","Epoch 32/100\n","469/469 - 4s - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0235 - val_acc: 0.9941 - 4s/epoch - 8ms/step\n","Epoch 33/100\n","469/469 - 4s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0311 - val_acc: 0.9926 - 4s/epoch - 8ms/step\n","Epoch 34/100\n","469/469 - 3s - loss: 0.0067 - acc: 0.9976 - val_loss: 0.0283 - val_acc: 0.9929 - 3s/epoch - 7ms/step\n","Epoch 35/100\n","469/469 - 4s - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0261 - val_acc: 0.9939 - 4s/epoch - 8ms/step\n","Epoch 36/100\n","469/469 - 4s - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0238 - val_acc: 0.9941 - 4s/epoch - 8ms/step\n","Epoch 37/100\n","469/469 - 3s - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0285 - val_acc: 0.9933 - 3s/epoch - 7ms/step\n","Epoch 38/100\n","469/469 - 4s - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0266 - val_acc: 0.9948 - 4s/epoch - 8ms/step\n","Epoch 39/100\n","469/469 - 4s - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0288 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 40/100\n","469/469 - 3s - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0314 - val_acc: 0.9937 - 3s/epoch - 7ms/step\n","Epoch 41/100\n","469/469 - 4s - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0321 - val_acc: 0.9939 - 4s/epoch - 8ms/step\n","Epoch 42/100\n","469/469 - 4s - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0265 - val_acc: 0.9953 - 4s/epoch - 8ms/step\n","Epoch 43/100\n","469/469 - 4s - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0280 - val_acc: 0.9937 - 4s/epoch - 8ms/step\n","Epoch 44/100\n","469/469 - 3s - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0297 - val_acc: 0.9940 - 3s/epoch - 7ms/step\n","Epoch 45/100\n","469/469 - 4s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0282 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 46/100\n","469/469 - 4s - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0227 - val_acc: 0.9949 - 4s/epoch - 8ms/step\n","Epoch 47/100\n","469/469 - 3s - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0220 - val_acc: 0.9953 - 3s/epoch - 7ms/step\n","Epoch 48/100\n","469/469 - 3s - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0325 - val_acc: 0.9935 - 3s/epoch - 7ms/step\n","Epoch 49/100\n","469/469 - 4s - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0241 - val_acc: 0.9947 - 4s/epoch - 8ms/step\n","Epoch 50/100\n","469/469 - 3s - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0252 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 51/100\n","469/469 - 4s - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0278 - val_acc: 0.9953 - 4s/epoch - 7ms/step\n","Epoch 52/100\n","469/469 - 4s - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0248 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 53/100\n","469/469 - 4s - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0277 - val_acc: 0.9945 - 4s/epoch - 8ms/step\n","Epoch 54/100\n","469/469 - 3s - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0277 - val_acc: 0.9947 - 3s/epoch - 7ms/step\n","Epoch 55/100\n","469/469 - 3s - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0282 - val_acc: 0.9947 - 3s/epoch - 7ms/step\n","Epoch 56/100\n","469/469 - 4s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0273 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 57/100\n","469/469 - 3s - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0233 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 58/100\n","469/469 - 4s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0284 - val_acc: 0.9949 - 4s/epoch - 8ms/step\n","Epoch 59/100\n","469/469 - 4s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0274 - val_acc: 0.9939 - 4s/epoch - 8ms/step\n","Epoch 60/100\n","469/469 - 4s - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0278 - val_acc: 0.9935 - 4s/epoch - 8ms/step\n","Epoch 61/100\n","469/469 - 3s - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0253 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 62/100\n","469/469 - 3s - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0271 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 63/100\n","469/469 - 4s - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0290 - val_acc: 0.9931 - 4s/epoch - 8ms/step\n","Epoch 64/100\n","469/469 - 3s - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0345 - val_acc: 0.9931 - 3s/epoch - 7ms/step\n","Epoch 65/100\n","469/469 - 3s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0306 - val_acc: 0.9939 - 3s/epoch - 7ms/step\n","Epoch 66/100\n","469/469 - 4s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0311 - val_acc: 0.9941 - 4s/epoch - 8ms/step\n","Epoch 67/100\n","469/469 - 4s - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0310 - val_acc: 0.9945 - 4s/epoch - 8ms/step\n","Epoch 68/100\n","469/469 - 3s - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0330 - val_acc: 0.9945 - 3s/epoch - 7ms/step\n","Epoch 69/100\n","469/469 - 4s - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0290 - val_acc: 0.9942 - 4s/epoch - 7ms/step\n","Epoch 70/100\n","469/469 - 4s - loss: 0.0035 - acc: 0.9987 - val_loss: 0.0350 - val_acc: 0.9944 - 4s/epoch - 8ms/step\n","Epoch 71/100\n","469/469 - 3s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0335 - val_acc: 0.9936 - 3s/epoch - 7ms/step\n","Epoch 72/100\n","469/469 - 3s - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0429 - val_acc: 0.9925 - 3s/epoch - 7ms/step\n","Epoch 73/100\n","469/469 - 4s - loss: 0.0029 - acc: 0.9988 - val_loss: 0.0329 - val_acc: 0.9939 - 4s/epoch - 8ms/step\n","Epoch 74/100\n","469/469 - 4s - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0344 - val_acc: 0.9938 - 4s/epoch - 8ms/step\n","Epoch 75/100\n","469/469 - 4s - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0368 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 76/100\n","469/469 - 4s - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0385 - val_acc: 0.9936 - 4s/epoch - 7ms/step\n","Epoch 77/100\n","469/469 - 4s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0362 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 78/100\n","469/469 - 3s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0325 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 79/100\n","469/469 - 3s - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0339 - val_acc: 0.9947 - 3s/epoch - 7ms/step\n","Epoch 80/100\n","469/469 - 4s - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0337 - val_acc: 0.9936 - 4s/epoch - 8ms/step\n","Epoch 81/100\n","469/469 - 3s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0335 - val_acc: 0.9935 - 3s/epoch - 7ms/step\n","Epoch 82/100\n","469/469 - 3s - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0353 - val_acc: 0.9940 - 3s/epoch - 7ms/step\n","Epoch 83/100\n","469/469 - 3s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0304 - val_acc: 0.9947 - 3s/epoch - 7ms/step\n","Epoch 84/100\n","469/469 - 4s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0310 - val_acc: 0.9946 - 4s/epoch - 8ms/step\n","Epoch 85/100\n","469/469 - 4s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0331 - val_acc: 0.9947 - 4s/epoch - 8ms/step\n","Epoch 86/100\n","469/469 - 3s - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0302 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 87/100\n","469/469 - 4s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0294 - val_acc: 0.9946 - 4s/epoch - 8ms/step\n","Epoch 88/100\n","469/469 - 4s - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0315 - val_acc: 0.9946 - 4s/epoch - 8ms/step\n","Epoch 89/100\n","469/469 - 3s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0350 - val_acc: 0.9948 - 3s/epoch - 7ms/step\n","Epoch 90/100\n","469/469 - 4s - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0370 - val_acc: 0.9937 - 4s/epoch - 8ms/step\n","Epoch 91/100\n","469/469 - 4s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0273 - val_acc: 0.9942 - 4s/epoch - 8ms/step\n","Epoch 92/100\n","469/469 - 3s - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0320 - val_acc: 0.9951 - 3s/epoch - 7ms/step\n","Epoch 93/100\n","469/469 - 3s - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0307 - val_acc: 0.9950 - 3s/epoch - 7ms/step\n","Epoch 94/100\n","469/469 - 4s - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0343 - val_acc: 0.9945 - 4s/epoch - 8ms/step\n","Epoch 95/100\n","469/469 - 3s - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0321 - val_acc: 0.9946 - 3s/epoch - 7ms/step\n","Epoch 96/100\n","469/469 - 3s - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0359 - val_acc: 0.9939 - 3s/epoch - 7ms/step\n","Epoch 97/100\n","469/469 - 4s - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0394 - val_acc: 0.9940 - 4s/epoch - 8ms/step\n","Epoch 98/100\n","469/469 - 4s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0318 - val_acc: 0.9946 - 4s/epoch - 8ms/step\n","Epoch 99/100\n","469/469 - 4s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0317 - val_acc: 0.9940 - 4s/epoch - 7ms/step\n","Epoch 100/100\n","469/469 - 3s - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0316 - val_acc: 0.9939 - 3s/epoch - 7ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.losses import categorical_crossentropy\n","\n","(train_x, train_y), (test_x, test_y) = mnist.load_data()\n","s_train_x = train_x.reshape(-1, 28, 28, 1) / 255.0\n","s_test_x = test_x.reshape(-1, 28, 28, 1) /255.0\n","s_train_y = to_categorical(train_y)\n","s_test_y = to_categorical(test_y)\n","\n","m =Sequential()\n","m.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = s_train_x.shape[1:]))\n","m.add(Conv2D(32, (3, 3), activation = 'relu'))\n","m.add(MaxPooling2D(2))\n","m.add(Dropout(0.25))\n","m.add(Conv2D(64, (3, 3), activation = 'relu'))\n","m.add(Conv2D(64, (3, 3), activation = 'relu'))\n","m.add(MaxPooling2D(2))\n","m.add(Dropout(0.25))\n","m.add(Flatten())\n","m.add(Dense(10, activation = 'softmax'))\n","m.compile(optimizer = Adam(learning_rate = 0.001),\n","          loss = 'categorical_crossentropy', metrics = 'acc')\n","hy = m.fit(s_train_x, s_train_y, validation_data = (s_test_x, s_test_y),\n","           batch_size = 128, epochs = 100, verbose = 2)\n","m.save('m3.h5')\n","\n"]}]}